{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "\n",
    "from sklearn.model_selection import StratifiedKFold,StratifiedShuffleSplit,train_test_split\n",
    "\n",
    "from keras.utils import to_categorical\n",
    "from keras.optimizers import Adam, RMSprop, SGD\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.layers import Input, Dense, Conv2D, Flatten, Activation, MaxPooling2D, BatchNormalization, Dropout\n",
    "from keras.models import Model,Sequential\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint,ReduceLROnPlateau\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = pd.read_csv(\"../input/train.csv\")\n",
    "y = x[\"label\"]\n",
    "x.drop(\"label\",axis=1,inplace=True)\n",
    "test = pd.read_csv(\"../input/test.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "x = scaler.fit_transform(x)\n",
    "test = scaler.transform(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "_uuid": "e5ea790f49c1e2a7eea942557c6ba2764fc6f945"
   },
   "outputs": [],
   "source": [
    "x_train,x_test,y_train,y_test = train_test_split(x,y,test_size=0.4, stratify=y, random_state=45)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = x_train.reshape(-1,28,28,1)\n",
    "x_test = x_test.reshape(-1,28,28,1)\n",
    "test = test.reshape(-1,28,28,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "_uuid": "defa23bf42c62a7ed1417b38674f57ae25616aec"
   },
   "outputs": [],
   "source": [
    "def cnn():\n",
    "    np.random.seed(0)\n",
    "    inp = Input( shape=(28,28, 1) )\n",
    "    \n",
    "    conv1 = Conv2D( filters=32, kernel_size=(3,3), strides=(1,1), padding='same' ) (inp)\n",
    "    conv1 = BatchNormalization()(conv1)\n",
    "    conv1 = Activation('relu')(conv1)\n",
    "    conv1 = MaxPooling2D()(conv1)\n",
    "    \n",
    "    conv2 = Conv2D( filters=64, kernel_size=(3,3), strides=(1,1), padding='same' ) (conv1)\n",
    "    conv2 = BatchNormalization()(conv2)\n",
    "    conv2 = Activation('relu')(conv2)\n",
    "    conv2 = MaxPooling2D()(conv2)\n",
    "    \n",
    "    conv3 = Conv2D( filters=128, kernel_size=(2,2), strides=(1,1), padding='same' ) (conv2)\n",
    "    conv3 = BatchNormalization()(conv3)\n",
    "    conv3 = Activation('relu')(conv3)\n",
    "    conv3 = MaxPooling2D()(conv3)\n",
    "    \n",
    "    conv4 = Conv2D( filters=256, kernel_size=(2,2), strides=(1,1), padding='same' ) (conv3)\n",
    "    conv4 = BatchNormalization()(conv4)\n",
    "    conv4 = Activation('relu')(conv4)\n",
    "    conv4 = MaxPooling2D()(conv4)\n",
    "\n",
    "    \n",
    "    fc = Flatten()(conv4)\n",
    "    \n",
    "    fc = Dense(128,activation=\"relu\")(fc)\n",
    "    fc = Dropout(.2)(fc)\n",
    "    \n",
    "    fc = Dense(64,activation=\"relu\")(fc)\n",
    "    fc = Dropout(.2)(fc)\n",
    "    \n",
    "    fc = Dense(10)(fc)\n",
    "    outp = Activation('softmax')(fc)\n",
    "    \n",
    "    model = Model(inp, outp)\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "_uuid": "efb4437ed7da1ee4d1bcb3414c8b5a0f25ddcc99"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         (None, 28, 28, 1)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 28, 28, 32)        320       \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch (None, 28, 28, 32)        128       \n",
      "_________________________________________________________________\n",
      "activation_1 (Activation)    (None, 28, 28, 32)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 14, 14, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 14, 14, 64)        18496     \n",
      "_________________________________________________________________\n",
      "batch_normalization_2 (Batch (None, 14, 14, 64)        256       \n",
      "_________________________________________________________________\n",
      "activation_2 (Activation)    (None, 14, 14, 64)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 7, 7, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 7, 7, 128)         32896     \n",
      "_________________________________________________________________\n",
      "batch_normalization_3 (Batch (None, 7, 7, 128)         512       \n",
      "_________________________________________________________________\n",
      "activation_3 (Activation)    (None, 7, 7, 128)         0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2 (None, 3, 3, 128)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_4 (Conv2D)            (None, 3, 3, 256)         131328    \n",
      "_________________________________________________________________\n",
      "batch_normalization_4 (Batch (None, 3, 3, 256)         1024      \n",
      "_________________________________________________________________\n",
      "activation_4 (Activation)    (None, 3, 3, 256)         0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_4 (MaxPooling2 (None, 1, 1, 256)         0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 128)               32896     \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 64)                8256      \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 10)                650       \n",
      "_________________________________________________________________\n",
      "activation_5 (Activation)    (None, 10)                0         \n",
      "=================================================================\n",
      "Total params: 226,762\n",
      "Trainable params: 225,802\n",
      "Non-trainable params: 960\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "cnn().summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = cnn()\n",
    "model.compile(loss='categorical_crossentropy', optimizer=Adam(), metrics=['acc'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "_uuid": "493dcb9a215b0cdd6705df0a63616cd5891bbd21",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "im_generator = ImageDataGenerator(rotation_range=10,\n",
    "                                 width_shift_range=0.1,\n",
    "                                 height_shift_range=0.1,\n",
    "                                 zoom_range=[0.9, 1],\n",
    "                                 horizontal_flip=True,\n",
    "                                 vertical_flip=False,\n",
    "                                 data_format=\"channels_last\",\n",
    "                                 dtype=np.ndarray)\n",
    "\n",
    "im_generator.fit(x_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      " - 6s - loss: 2.3709 - acc: 0.2221 - val_loss: 1.9648 - val_acc: 0.2936\n",
      "Epoch 2/100\n",
      " - 1s - loss: 1.8535 - acc: 0.3823 - val_loss: 1.6809 - val_acc: 0.4398\n",
      "Epoch 3/100\n",
      " - 3s - loss: 1.5512 - acc: 0.4765 - val_loss: 1.4569 - val_acc: 0.5126\n",
      "Epoch 4/100\n",
      " - 3s - loss: 1.3018 - acc: 0.5667 - val_loss: 1.2777 - val_acc: 0.5473\n",
      "Epoch 5/100\n",
      " - 3s - loss: 1.0917 - acc: 0.6425 - val_loss: 0.9278 - val_acc: 0.6832\n",
      "Epoch 6/100\n",
      " - 2s - loss: 0.8993 - acc: 0.7030 - val_loss: 1.0180 - val_acc: 0.6503\n",
      "Epoch 7/100\n",
      " - 3s - loss: 0.7551 - acc: 0.7463 - val_loss: 0.5407 - val_acc: 0.8361\n",
      "Epoch 8/100\n",
      " - 2s - loss: 0.6386 - acc: 0.7854 - val_loss: 0.7714 - val_acc: 0.7513\n",
      "Epoch 9/100\n",
      " - 3s - loss: 0.5730 - acc: 0.8162 - val_loss: 0.4035 - val_acc: 0.8750\n",
      "Epoch 10/100\n",
      " - 3s - loss: 0.5153 - acc: 0.8301 - val_loss: 0.3963 - val_acc: 0.8684\n",
      "Epoch 11/100\n",
      " - 2s - loss: 0.4713 - acc: 0.8469 - val_loss: 0.3430 - val_acc: 0.8973\n",
      "Epoch 12/100\n",
      " - 3s - loss: 0.4190 - acc: 0.8685 - val_loss: 0.3309 - val_acc: 0.8935\n",
      "Epoch 13/100\n",
      " - 2s - loss: 0.3850 - acc: 0.8774 - val_loss: 0.3022 - val_acc: 0.9049\n",
      "Epoch 14/100\n",
      " - 3s - loss: 0.3503 - acc: 0.8937 - val_loss: 0.2926 - val_acc: 0.9027\n",
      "Epoch 15/100\n",
      " - 3s - loss: 0.3132 - acc: 0.9035 - val_loss: 0.3393 - val_acc: 0.8875\n",
      "Epoch 16/100\n",
      " - 3s - loss: 0.2966 - acc: 0.9070 - val_loss: 0.2537 - val_acc: 0.9226\n",
      "Epoch 17/100\n",
      " - 3s - loss: 0.2888 - acc: 0.9111 - val_loss: 0.3165 - val_acc: 0.8938\n",
      "Epoch 18/100\n",
      " - 3s - loss: 0.2734 - acc: 0.9188 - val_loss: 0.2671 - val_acc: 0.9132\n",
      "Epoch 19/100\n",
      " - 3s - loss: 0.2539 - acc: 0.9213 - val_loss: 0.2733 - val_acc: 0.9129\n",
      "\n",
      "Epoch 00019: ReduceLROnPlateau reducing learning rate to 0.0006000000284984708.\n",
      "Epoch 20/100\n",
      " - 3s - loss: 0.2403 - acc: 0.9295 - val_loss: 0.2219 - val_acc: 0.9310\n",
      "Epoch 21/100\n",
      " - 2s - loss: 0.2171 - acc: 0.9351 - val_loss: 0.1892 - val_acc: 0.9411\n",
      "Epoch 22/100\n",
      " - 3s - loss: 0.2223 - acc: 0.9351 - val_loss: 0.1892 - val_acc: 0.9412\n",
      "Epoch 23/100\n",
      " - 3s - loss: 0.2109 - acc: 0.9360 - val_loss: 0.1743 - val_acc: 0.9452\n",
      "Epoch 24/100\n",
      " - 2s - loss: 0.2049 - acc: 0.9388 - val_loss: 0.2763 - val_acc: 0.9102\n",
      "Epoch 25/100\n",
      " - 3s - loss: 0.1953 - acc: 0.9413 - val_loss: 0.1548 - val_acc: 0.9529\n",
      "Epoch 26/100\n",
      " - 2s - loss: 0.1887 - acc: 0.9436 - val_loss: 0.1748 - val_acc: 0.9463\n",
      "Epoch 27/100\n",
      " - 3s - loss: 0.1859 - acc: 0.9434 - val_loss: 0.1416 - val_acc: 0.9571\n",
      "Epoch 28/100\n",
      " - 3s - loss: 0.1823 - acc: 0.9448 - val_loss: 0.2337 - val_acc: 0.9262\n",
      "Epoch 29/100\n",
      " - 3s - loss: 0.1747 - acc: 0.9503 - val_loss: 0.1215 - val_acc: 0.9627\n",
      "Epoch 30/100\n",
      " - 3s - loss: 0.1777 - acc: 0.9495 - val_loss: 0.1567 - val_acc: 0.9511\n",
      "Epoch 31/100\n",
      " - 3s - loss: 0.1737 - acc: 0.9476 - val_loss: 0.1485 - val_acc: 0.9547\n",
      "Epoch 32/100\n",
      " - 2s - loss: 0.1746 - acc: 0.9508 - val_loss: 0.1952 - val_acc: 0.9419\n",
      "\n",
      "Epoch 00032: ReduceLROnPlateau reducing learning rate to 0.0003600000170990825.\n",
      "Epoch 33/100\n",
      " - 3s - loss: 0.1598 - acc: 0.9548 - val_loss: 0.2062 - val_acc: 0.9343\n",
      "Epoch 34/100\n",
      " - 2s - loss: 0.1654 - acc: 0.9530 - val_loss: 0.1309 - val_acc: 0.9599\n",
      "Epoch 35/100\n",
      " - 3s - loss: 0.1587 - acc: 0.9539 - val_loss: 0.1216 - val_acc: 0.9630\n",
      "Epoch 36/100\n",
      " - 3s - loss: 0.1536 - acc: 0.9552 - val_loss: 0.1203 - val_acc: 0.9625\n",
      "Epoch 37/100\n",
      " - 3s - loss: 0.1548 - acc: 0.9524 - val_loss: 0.1430 - val_acc: 0.9563\n",
      "Epoch 38/100\n",
      " - 3s - loss: 0.1461 - acc: 0.9566 - val_loss: 0.1255 - val_acc: 0.9617\n",
      "Epoch 39/100\n",
      " - 2s - loss: 0.1375 - acc: 0.9590 - val_loss: 0.1098 - val_acc: 0.9664\n",
      "Epoch 40/100\n",
      " - 3s - loss: 0.1404 - acc: 0.9593 - val_loss: 0.1038 - val_acc: 0.9678\n",
      "Epoch 41/100\n",
      " - 3s - loss: 0.1375 - acc: 0.9576 - val_loss: 0.1023 - val_acc: 0.9677\n",
      "Epoch 42/100\n",
      " - 3s - loss: 0.1397 - acc: 0.9595 - val_loss: 0.1038 - val_acc: 0.9677\n",
      "Epoch 43/100\n",
      " - 3s - loss: 0.1328 - acc: 0.9600 - val_loss: 0.1011 - val_acc: 0.9685\n",
      "\n",
      "Epoch 00043: ReduceLROnPlateau reducing learning rate to 0.00021600000327453016.\n",
      "Epoch 44/100\n",
      " - 3s - loss: 0.1374 - acc: 0.9611 - val_loss: 0.1000 - val_acc: 0.9686\n",
      "Epoch 45/100\n",
      " - 2s - loss: 0.1325 - acc: 0.9598 - val_loss: 0.1031 - val_acc: 0.9673\n",
      "Epoch 46/100\n",
      " - 3s - loss: 0.1386 - acc: 0.9611 - val_loss: 0.1056 - val_acc: 0.9670\n",
      "Epoch 47/100\n",
      " - 2s - loss: 0.1268 - acc: 0.9649 - val_loss: 0.0959 - val_acc: 0.9708\n",
      "Epoch 48/100\n",
      " - 3s - loss: 0.1308 - acc: 0.9628 - val_loss: 0.0984 - val_acc: 0.9697\n",
      "Epoch 49/100\n",
      " - 3s - loss: 0.1214 - acc: 0.9641 - val_loss: 0.0951 - val_acc: 0.9718\n",
      "Epoch 50/100\n",
      " - 2s - loss: 0.1336 - acc: 0.9583 - val_loss: 0.1131 - val_acc: 0.9658\n",
      "Epoch 51/100\n",
      " - 3s - loss: 0.1220 - acc: 0.9642 - val_loss: 0.1011 - val_acc: 0.9690\n",
      "Epoch 52/100\n",
      " - 2s - loss: 0.1312 - acc: 0.9630 - val_loss: 0.0959 - val_acc: 0.9703\n",
      "\n",
      "Epoch 00052: ReduceLROnPlateau reducing learning rate to 0.00012960000021848827.\n",
      "Epoch 53/100\n",
      " - 3s - loss: 0.1215 - acc: 0.9636 - val_loss: 0.1134 - val_acc: 0.9655\n",
      "Epoch 54/100\n",
      " - 3s - loss: 0.1273 - acc: 0.9619 - val_loss: 0.1162 - val_acc: 0.9642\n",
      "Epoch 55/100\n",
      " - 2s - loss: 0.1153 - acc: 0.9672 - val_loss: 0.1062 - val_acc: 0.9676\n",
      "Epoch 56/100\n",
      " - 3s - loss: 0.1233 - acc: 0.9638 - val_loss: 0.0912 - val_acc: 0.9720\n",
      "Epoch 57/100\n",
      " - 3s - loss: 0.1188 - acc: 0.9672 - val_loss: 0.1022 - val_acc: 0.9693\n",
      "Epoch 58/100\n",
      " - 3s - loss: 0.1115 - acc: 0.9677 - val_loss: 0.1258 - val_acc: 0.9611\n",
      "Epoch 59/100\n",
      " - 3s - loss: 0.1173 - acc: 0.9647 - val_loss: 0.1162 - val_acc: 0.9646\n",
      "\n",
      "Epoch 00059: ReduceLROnPlateau reducing learning rate to 0.0001.\n",
      "Epoch 60/100\n",
      " - 3s - loss: 0.1306 - acc: 0.9629 - val_loss: 0.1047 - val_acc: 0.9685\n",
      "Epoch 61/100\n",
      " - 3s - loss: 0.1196 - acc: 0.9664 - val_loss: 0.0969 - val_acc: 0.9707\n",
      "Epoch 62/100\n",
      " - 3s - loss: 0.1116 - acc: 0.9682 - val_loss: 0.0943 - val_acc: 0.9712\n",
      "Epoch 63/100\n",
      " - 2s - loss: 0.1117 - acc: 0.9668 - val_loss: 0.0953 - val_acc: 0.9707\n",
      "Epoch 64/100\n",
      " - 3s - loss: 0.1162 - acc: 0.9654 - val_loss: 0.1026 - val_acc: 0.9693\n",
      "Epoch 65/100\n",
      " - 2s - loss: 0.1214 - acc: 0.9646 - val_loss: 0.1017 - val_acc: 0.9690\n",
      "Epoch 66/100\n",
      " - 3s - loss: 0.1215 - acc: 0.9638 - val_loss: 0.0892 - val_acc: 0.9723\n",
      "Epoch 67/100\n",
      " - 3s - loss: 0.1086 - acc: 0.9655 - val_loss: 0.0852 - val_acc: 0.9741\n",
      "Epoch 68/100\n",
      " - 2s - loss: 0.1161 - acc: 0.9637 - val_loss: 0.0948 - val_acc: 0.9708\n",
      "Epoch 69/100\n",
      " - 3s - loss: 0.1219 - acc: 0.9661 - val_loss: 0.1268 - val_acc: 0.9607\n",
      "Epoch 70/100\n",
      " - 3s - loss: 0.1146 - acc: 0.9671 - val_loss: 0.1216 - val_acc: 0.9624\n",
      "Epoch 71/100\n",
      " - 3s - loss: 0.1164 - acc: 0.9646 - val_loss: 0.1034 - val_acc: 0.9682\n",
      "Epoch 72/100\n",
      " - 3s - loss: 0.1129 - acc: 0.9680 - val_loss: 0.1023 - val_acc: 0.9685\n",
      "Epoch 73/100\n",
      " - 3s - loss: 0.1107 - acc: 0.9655 - val_loss: 0.1078 - val_acc: 0.9667\n",
      "Epoch 74/100\n",
      " - 3s - loss: 0.1150 - acc: 0.9648 - val_loss: 0.1018 - val_acc: 0.9689\n",
      "Epoch 75/100\n",
      " - 3s - loss: 0.1034 - acc: 0.9686 - val_loss: 0.0927 - val_acc: 0.9715\n",
      "Epoch 76/100\n",
      " - 2s - loss: 0.1097 - acc: 0.9677 - val_loss: 0.0978 - val_acc: 0.9701\n",
      "Epoch 77/100\n",
      " - 3s - loss: 0.1109 - acc: 0.9689 - val_loss: 0.1121 - val_acc: 0.9651\n",
      "Epoch 78/100\n",
      " - 2s - loss: 0.1209 - acc: 0.9643 - val_loss: 0.1075 - val_acc: 0.9676\n",
      "Epoch 79/100\n",
      " - 3s - loss: 0.1200 - acc: 0.9633 - val_loss: 0.1062 - val_acc: 0.9679\n",
      "Epoch 80/100\n",
      " - 3s - loss: 0.0978 - acc: 0.9714 - val_loss: 0.1054 - val_acc: 0.9677\n",
      "Epoch 81/100\n",
      " - 3s - loss: 0.1049 - acc: 0.9694 - val_loss: 0.1026 - val_acc: 0.9684\n",
      "Epoch 82/100\n",
      " - 3s - loss: 0.1073 - acc: 0.9684 - val_loss: 0.0952 - val_acc: 0.9699\n",
      "Epoch 83/100\n",
      " - 3s - loss: 0.1063 - acc: 0.9690 - val_loss: 0.0933 - val_acc: 0.9711\n",
      "Epoch 84/100\n",
      " - 3s - loss: 0.1058 - acc: 0.9693 - val_loss: 0.0943 - val_acc: 0.9706\n",
      "Epoch 85/100\n",
      " - 3s - loss: 0.1115 - acc: 0.9701 - val_loss: 0.1063 - val_acc: 0.9678\n",
      "Epoch 86/100\n",
      " - 3s - loss: 0.1050 - acc: 0.9683 - val_loss: 0.0931 - val_acc: 0.9714\n",
      "Epoch 87/100\n",
      " - 3s - loss: 0.1083 - acc: 0.9664 - val_loss: 0.0848 - val_acc: 0.9740\n",
      "Epoch 88/100\n",
      " - 3s - loss: 0.1114 - acc: 0.9660 - val_loss: 0.0943 - val_acc: 0.9710\n",
      "Epoch 89/100\n",
      " - 3s - loss: 0.0983 - acc: 0.9712 - val_loss: 0.1161 - val_acc: 0.9651\n",
      "Epoch 90/100\n",
      " - 3s - loss: 0.1120 - acc: 0.9645 - val_loss: 0.1099 - val_acc: 0.9667\n",
      "Epoch 91/100\n",
      " - 2s - loss: 0.1088 - acc: 0.9687 - val_loss: 0.0884 - val_acc: 0.9726\n",
      "Epoch 92/100\n",
      " - 3s - loss: 0.1114 - acc: 0.9673 - val_loss: 0.0854 - val_acc: 0.9739\n",
      "Epoch 93/100\n",
      " - 3s - loss: 0.1127 - acc: 0.9678 - val_loss: 0.1099 - val_acc: 0.9678\n",
      "Epoch 94/100\n",
      " - 3s - loss: 0.1009 - acc: 0.9693 - val_loss: 0.1055 - val_acc: 0.9691\n",
      "Epoch 95/100\n",
      " - 3s - loss: 0.1075 - acc: 0.9687 - val_loss: 0.0936 - val_acc: 0.9720\n",
      "Epoch 96/100\n",
      " - 3s - loss: 0.1057 - acc: 0.9696 - val_loss: 0.0847 - val_acc: 0.9736\n",
      "Epoch 97/100\n",
      " - 3s - loss: 0.1037 - acc: 0.9702 - val_loss: 0.0915 - val_acc: 0.9717\n",
      "Epoch 98/100\n",
      " - 3s - loss: 0.1061 - acc: 0.9679 - val_loss: 0.0980 - val_acc: 0.9710\n",
      "Epoch 99/100\n",
      " - 3s - loss: 0.0890 - acc: 0.9728 - val_loss: 0.0999 - val_acc: 0.9692\n",
      "Epoch 100/100\n",
      " - 3s - loss: 0.1002 - acc: 0.9713 - val_loss: 0.0909 - val_acc: 0.9724\n"
     ]
    }
   ],
   "source": [
    "model_check_pt = ModelCheckpoint('./best_model.h5',monitor='val_acc', save_best_only=True, mode='max')\n",
    "reduce_lr = ReduceLROnPlateau(monitor=\"val_acc\", factor=0.6, patience=3, mode=\"max\", cooldown=5, \n",
    "                              min_lr=0.0001, min_delta=0.001, verbose=1 )\n",
    "\n",
    "hist = model.fit_generator(generator=im_generator.flow(x_train, to_categorical(y_train), batch_size=2000),\n",
    "                           validation_data=(x_test,to_categorical(y_test)),\n",
    "                           epochs=100,\n",
    "                           steps_per_epoch=5,\n",
    "                           verbose=2,\n",
    "                           validation_steps=1,\n",
    "                           use_multiprocessing=True,\n",
    "                           callbacks=[model_check_pt,reduce_lr])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 31497 samples, validate on 10503 samples\n",
      "Epoch 1/20\n",
      "31497/31497 [==============================] - 4s 129us/step - loss: 0.0938 - acc: 0.9725 - val_loss: 0.0746 - val_acc: 0.9778\n",
      "Epoch 2/20\n",
      "31497/31497 [==============================] - 1s 38us/step - loss: 0.0497 - acc: 0.9858 - val_loss: 0.0791 - val_acc: 0.9777\n",
      "Epoch 3/20\n",
      "31497/31497 [==============================] - 1s 37us/step - loss: 0.0331 - acc: 0.9895 - val_loss: 0.0622 - val_acc: 0.9836\n",
      "Epoch 4/20\n",
      "31497/31497 [==============================] - 1s 37us/step - loss: 0.0259 - acc: 0.9924 - val_loss: 0.0603 - val_acc: 0.9831\n",
      "Epoch 5/20\n",
      "31497/31497 [==============================] - 1s 38us/step - loss: 0.0197 - acc: 0.9939 - val_loss: 0.0923 - val_acc: 0.9773\n",
      "Epoch 6/20\n",
      "31497/31497 [==============================] - 1s 38us/step - loss: 0.0170 - acc: 0.9950 - val_loss: 0.0740 - val_acc: 0.9812\n",
      "\n",
      "Epoch 00006: ReduceLROnPlateau reducing learning rate to 0.0006000000284984708.\n",
      "Epoch 7/20\n",
      "31497/31497 [==============================] - 1s 38us/step - loss: 0.0097 - acc: 0.9974 - val_loss: 0.0405 - val_acc: 0.9892\n",
      "Epoch 8/20\n",
      "31497/31497 [==============================] - 1s 38us/step - loss: 0.0066 - acc: 0.9982 - val_loss: 0.0711 - val_acc: 0.9815\n",
      "Epoch 9/20\n",
      "31497/31497 [==============================] - 1s 38us/step - loss: 0.0059 - acc: 0.9984 - val_loss: 0.0460 - val_acc: 0.9888\n",
      "Epoch 10/20\n",
      "31497/31497 [==============================] - 1s 38us/step - loss: 0.0047 - acc: 0.9985 - val_loss: 0.0432 - val_acc: 0.9904\n",
      "Epoch 11/20\n",
      "31497/31497 [==============================] - 1s 37us/step - loss: 0.0048 - acc: 0.9984 - val_loss: 0.0518 - val_acc: 0.9871\n",
      "Epoch 12/20\n",
      "31497/31497 [==============================] - 1s 37us/step - loss: 0.0034 - acc: 0.9990 - val_loss: 0.0440 - val_acc: 0.9894\n",
      "Epoch 13/20\n",
      "31497/31497 [==============================] - 1s 38us/step - loss: 0.0029 - acc: 0.9993 - val_loss: 0.0451 - val_acc: 0.9908\n",
      "\n",
      "Epoch 00013: ReduceLROnPlateau reducing learning rate to 0.0003600000170990825.\n",
      "Epoch 14/20\n",
      "31497/31497 [==============================] - 1s 37us/step - loss: 0.0024 - acc: 0.9994 - val_loss: 0.0466 - val_acc: 0.9896\n",
      "Epoch 15/20\n",
      "31497/31497 [==============================] - 1s 38us/step - loss: 0.0026 - acc: 0.9993 - val_loss: 0.0443 - val_acc: 0.9891\n",
      "Epoch 16/20\n",
      "31497/31497 [==============================] - 1s 38us/step - loss: 0.0021 - acc: 0.9997 - val_loss: 0.0411 - val_acc: 0.9909\n",
      "Epoch 17/20\n",
      "31497/31497 [==============================] - 1s 38us/step - loss: 0.0020 - acc: 0.9995 - val_loss: 0.0446 - val_acc: 0.9907\n",
      "Epoch 18/20\n",
      "31497/31497 [==============================] - 1s 38us/step - loss: 0.0016 - acc: 0.9997 - val_loss: 0.0457 - val_acc: 0.9898\n",
      "Epoch 19/20\n",
      "31497/31497 [==============================] - 1s 38us/step - loss: 0.0018 - acc: 0.9996 - val_loss: 0.0465 - val_acc: 0.9900\n",
      "Epoch 20/20\n",
      "31497/31497 [==============================] - 1s 38us/step - loss: 0.0016 - acc: 0.9996 - val_loss: 0.0417 - val_acc: 0.9911\n",
      "\n",
      "Epoch 00020: ReduceLROnPlateau reducing learning rate to 0.00021600000327453016.\n",
      "Train on 31500 samples, validate on 10500 samples\n",
      "Epoch 1/20\n",
      "31500/31500 [==============================] - 3s 96us/step - loss: 0.0307 - acc: 0.9919 - val_loss: 0.0173 - val_acc: 0.9943\n",
      "Epoch 2/20\n",
      "31500/31500 [==============================] - 1s 37us/step - loss: 0.0164 - acc: 0.9950 - val_loss: 0.0167 - val_acc: 0.9943\n",
      "Epoch 3/20\n",
      "31500/31500 [==============================] - 1s 38us/step - loss: 0.0110 - acc: 0.9972 - val_loss: 0.0095 - val_acc: 0.9967\n",
      "Epoch 4/20\n",
      "31500/31500 [==============================] - 1s 37us/step - loss: 0.0093 - acc: 0.9970 - val_loss: 0.0380 - val_acc: 0.9891\n",
      "Epoch 5/20\n",
      "31500/31500 [==============================] - 1s 38us/step - loss: 0.0096 - acc: 0.9972 - val_loss: 0.0262 - val_acc: 0.9899\n",
      "Epoch 6/20\n",
      "31500/31500 [==============================] - 1s 38us/step - loss: 0.0071 - acc: 0.9981 - val_loss: 0.0465 - val_acc: 0.9903\n",
      "\n",
      "Epoch 00006: ReduceLROnPlateau reducing learning rate to 0.0006000000284984708.\n",
      "Epoch 7/20\n",
      "31500/31500 [==============================] - 1s 38us/step - loss: 0.0075 - acc: 0.9975 - val_loss: 0.0252 - val_acc: 0.9929\n",
      "Epoch 8/20\n",
      "31500/31500 [==============================] - 1s 38us/step - loss: 0.0036 - acc: 0.9991 - val_loss: 0.0137 - val_acc: 0.9958\n",
      "Epoch 9/20\n",
      "31500/31500 [==============================] - 1s 38us/step - loss: 0.0018 - acc: 0.9995 - val_loss: 0.0103 - val_acc: 0.9975\n",
      "Epoch 10/20\n",
      "31500/31500 [==============================] - 1s 38us/step - loss: 0.0026 - acc: 0.9991 - val_loss: 0.0193 - val_acc: 0.9946\n",
      "Epoch 11/20\n",
      "31500/31500 [==============================] - 1s 39us/step - loss: 0.0025 - acc: 0.9991 - val_loss: 0.0139 - val_acc: 0.9965\n",
      "Epoch 12/20\n",
      "31500/31500 [==============================] - 1s 37us/step - loss: 0.0013 - acc: 0.9997 - val_loss: 0.0120 - val_acc: 0.9968\n",
      "Epoch 13/20\n",
      "31500/31500 [==============================] - 1s 38us/step - loss: 0.0011 - acc: 0.9997 - val_loss: 0.0213 - val_acc: 0.9939\n",
      "\n",
      "Epoch 00013: ReduceLROnPlateau reducing learning rate to 0.0003600000170990825.\n",
      "Epoch 14/20\n",
      "31500/31500 [==============================] - 1s 41us/step - loss: 0.0014 - acc: 0.9996 - val_loss: 0.0191 - val_acc: 0.9959\n",
      "Epoch 15/20\n",
      "31500/31500 [==============================] - 1s 38us/step - loss: 7.9152e-04 - acc: 0.9998 - val_loss: 0.0101 - val_acc: 0.9971\n",
      "Epoch 16/20\n",
      "31500/31500 [==============================] - 1s 38us/step - loss: 8.3665e-04 - acc: 0.9998 - val_loss: 0.0114 - val_acc: 0.9972\n",
      "Epoch 17/20\n",
      "31500/31500 [==============================] - 1s 38us/step - loss: 5.1370e-04 - acc: 0.9999 - val_loss: 0.0113 - val_acc: 0.9973\n",
      "Epoch 18/20\n",
      "31500/31500 [==============================] - 1s 38us/step - loss: 4.7405e-04 - acc: 0.9999 - val_loss: 0.0154 - val_acc: 0.9962\n",
      "Epoch 19/20\n",
      "31500/31500 [==============================] - 1s 38us/step - loss: 8.4770e-04 - acc: 0.9997 - val_loss: 0.0115 - val_acc: 0.9972\n",
      "Epoch 20/20\n",
      "31500/31500 [==============================] - 1s 38us/step - loss: 4.6178e-04 - acc: 1.0000 - val_loss: 0.0135 - val_acc: 0.9969\n",
      "\n",
      "Epoch 00020: ReduceLROnPlateau reducing learning rate to 0.00021600000327453016.\n",
      "Train on 31500 samples, validate on 10500 samples\n",
      "Epoch 1/20\n",
      "31500/31500 [==============================] - 3s 97us/step - loss: 0.0185 - acc: 0.9945 - val_loss: 0.0099 - val_acc: 0.9968\n",
      "Epoch 2/20\n",
      "31500/31500 [==============================] - 1s 38us/step - loss: 0.0108 - acc: 0.9967 - val_loss: 0.0083 - val_acc: 0.9970\n",
      "Epoch 3/20\n",
      "31500/31500 [==============================] - 1s 38us/step - loss: 0.0070 - acc: 0.9978 - val_loss: 0.0125 - val_acc: 0.9957\n",
      "Epoch 4/20\n",
      "31500/31500 [==============================] - 1s 39us/step - loss: 0.0060 - acc: 0.9982 - val_loss: 0.0204 - val_acc: 0.9937\n",
      "\n",
      "Epoch 00004: ReduceLROnPlateau reducing learning rate to 0.0006000000284984708.\n",
      "Epoch 5/20\n",
      "31500/31500 [==============================] - 1s 39us/step - loss: 0.0038 - acc: 0.9987 - val_loss: 0.0078 - val_acc: 0.9977\n",
      "Epoch 6/20\n",
      "31500/31500 [==============================] - 1s 39us/step - loss: 0.0028 - acc: 0.9992 - val_loss: 0.0074 - val_acc: 0.9971\n",
      "Epoch 7/20\n",
      "31500/31500 [==============================] - 1s 39us/step - loss: 0.0023 - acc: 0.9995 - val_loss: 0.0050 - val_acc: 0.9983\n",
      "Epoch 8/20\n",
      "31500/31500 [==============================] - 1s 38us/step - loss: 0.0014 - acc: 0.9996 - val_loss: 0.0083 - val_acc: 0.9974\n",
      "Epoch 9/20\n",
      "31500/31500 [==============================] - 1s 39us/step - loss: 0.0016 - acc: 0.9994 - val_loss: 0.0036 - val_acc: 0.9987\n",
      "Epoch 10/20\n",
      "31500/31500 [==============================] - 1s 39us/step - loss: 0.0011 - acc: 0.9997 - val_loss: 0.0045 - val_acc: 0.9984\n",
      "Epoch 11/20\n",
      "31500/31500 [==============================] - 1s 39us/step - loss: 0.0014 - acc: 0.9995 - val_loss: 0.0076 - val_acc: 0.9975\n",
      "\n",
      "Epoch 00011: ReduceLROnPlateau reducing learning rate to 0.0003600000170990825.\n",
      "Epoch 12/20\n",
      "31500/31500 [==============================] - 1s 39us/step - loss: 8.5819e-04 - acc: 0.9998 - val_loss: 0.0028 - val_acc: 0.9991\n",
      "Epoch 13/20\n",
      "31500/31500 [==============================] - 1s 39us/step - loss: 5.8785e-04 - acc: 0.9999 - val_loss: 0.0083 - val_acc: 0.9977\n",
      "Epoch 14/20\n",
      "31500/31500 [==============================] - 1s 38us/step - loss: 3.5598e-04 - acc: 0.9999 - val_loss: 0.0028 - val_acc: 0.9988\n",
      "Epoch 15/20\n",
      "31500/31500 [==============================] - 1s 39us/step - loss: 3.7583e-04 - acc: 0.9999 - val_loss: 0.0028 - val_acc: 0.9991\n",
      "Epoch 16/20\n",
      "31500/31500 [==============================] - 1s 39us/step - loss: 5.0766e-04 - acc: 0.9998 - val_loss: 0.0063 - val_acc: 0.9979\n",
      "Epoch 17/20\n",
      "31500/31500 [==============================] - 1s 38us/step - loss: 4.0693e-04 - acc: 0.9999 - val_loss: 0.0037 - val_acc: 0.9984\n",
      "Epoch 18/20\n",
      "31500/31500 [==============================] - 1s 38us/step - loss: 3.0030e-04 - acc: 1.0000 - val_loss: 0.0056 - val_acc: 0.9985\n",
      "\n",
      "Epoch 00018: ReduceLROnPlateau reducing learning rate to 0.00021600000327453016.\n",
      "Epoch 19/20\n",
      "31500/31500 [==============================] - 1s 38us/step - loss: 2.5301e-04 - acc: 0.9999 - val_loss: 0.0025 - val_acc: 0.9993\n",
      "Epoch 20/20\n",
      "31500/31500 [==============================] - 1s 38us/step - loss: 2.1469e-04 - acc: 1.0000 - val_loss: 0.0023 - val_acc: 0.9991\n",
      "Train on 31503 samples, validate on 10497 samples\n",
      "Epoch 1/20\n",
      "31503/31503 [==============================] - 3s 109us/step - loss: 0.0129 - acc: 0.9963 - val_loss: 0.0299 - val_acc: 0.9898\n",
      "Epoch 2/20\n",
      "31503/31503 [==============================] - 1s 38us/step - loss: 0.0070 - acc: 0.9977 - val_loss: 0.0024 - val_acc: 0.9991\n",
      "Epoch 3/20\n",
      "31503/31503 [==============================] - 1s 38us/step - loss: 0.0061 - acc: 0.9977 - val_loss: 0.0091 - val_acc: 0.9973\n",
      "Epoch 4/20\n",
      "31503/31503 [==============================] - 1s 39us/step - loss: 0.0072 - acc: 0.9979 - val_loss: 0.0036 - val_acc: 0.9986\n",
      "Epoch 5/20\n",
      "31503/31503 [==============================] - 1s 38us/step - loss: 0.0062 - acc: 0.9982 - val_loss: 0.0205 - val_acc: 0.9945\n",
      "\n",
      "Epoch 00005: ReduceLROnPlateau reducing learning rate to 0.0006000000284984708.\n",
      "Epoch 6/20\n",
      "31503/31503 [==============================] - 1s 39us/step - loss: 0.0024 - acc: 0.9993 - val_loss: 0.0035 - val_acc: 0.9990\n",
      "Epoch 7/20\n",
      "31503/31503 [==============================] - 1s 38us/step - loss: 0.0016 - acc: 0.9995 - val_loss: 0.0016 - val_acc: 0.9993\n",
      "Epoch 8/20\n",
      "31503/31503 [==============================] - 1s 39us/step - loss: 7.2268e-04 - acc: 0.9998 - val_loss: 0.0044 - val_acc: 0.9989\n",
      "Epoch 9/20\n",
      "31503/31503 [==============================] - 1s 38us/step - loss: 7.0775e-04 - acc: 0.9998 - val_loss: 0.0016 - val_acc: 0.9995\n",
      "Epoch 10/20\n",
      "31503/31503 [==============================] - 1s 39us/step - loss: 0.0013 - acc: 0.9997 - val_loss: 0.0024 - val_acc: 0.9991\n",
      "Epoch 11/20\n",
      "31503/31503 [==============================] - 1s 38us/step - loss: 9.7122e-04 - acc: 0.9998 - val_loss: 0.0021 - val_acc: 0.9992\n",
      "Epoch 12/20\n",
      "31503/31503 [==============================] - 1s 39us/step - loss: 9.7987e-04 - acc: 0.9997 - val_loss: 0.0100 - val_acc: 0.9972\n",
      "\n",
      "Epoch 00012: ReduceLROnPlateau reducing learning rate to 0.0003600000170990825.\n",
      "Epoch 13/20\n",
      "31503/31503 [==============================] - 1s 38us/step - loss: 6.9733e-04 - acc: 0.9997 - val_loss: 0.0023 - val_acc: 0.9992\n",
      "Epoch 14/20\n",
      "31503/31503 [==============================] - 1s 38us/step - loss: 3.6308e-04 - acc: 0.9999 - val_loss: 0.0011 - val_acc: 0.9996\n",
      "Epoch 15/20\n",
      "31503/31503 [==============================] - 1s 38us/step - loss: 3.2662e-04 - acc: 0.9999 - val_loss: 0.0010 - val_acc: 0.9995\n",
      "Epoch 16/20\n",
      "31503/31503 [==============================] - 1s 38us/step - loss: 3.3657e-04 - acc: 0.9998 - val_loss: 7.4943e-04 - val_acc: 0.9997\n",
      "Epoch 17/20\n",
      "31503/31503 [==============================] - 1s 38us/step - loss: 2.2827e-04 - acc: 1.0000 - val_loss: 9.7808e-04 - val_acc: 0.9996\n",
      "Epoch 18/20\n",
      "31503/31503 [==============================] - 1s 38us/step - loss: 5.0232e-04 - acc: 0.9999 - val_loss: 0.0015 - val_acc: 0.9994\n",
      "Epoch 19/20\n",
      "31503/31503 [==============================] - 1s 38us/step - loss: 3.7200e-04 - acc: 0.9999 - val_loss: 0.0071 - val_acc: 0.9984\n",
      "\n",
      "Epoch 00019: ReduceLROnPlateau reducing learning rate to 0.00021600000327453016.\n",
      "Epoch 20/20\n",
      "31503/31503 [==============================] - 1s 38us/step - loss: 2.5369e-04 - acc: 0.9999 - val_loss: 0.0034 - val_acc: 0.9990\n"
     ]
    }
   ],
   "source": [
    "kfolder = StratifiedKFold(n_splits=4,random_state=45,shuffle=True)\n",
    "for train_index,test_index in kfolder.split(x,y):\n",
    "    x_train = x[train_index].reshape(-1,28,28,1)\n",
    "    y_train = y[train_index]\n",
    "    x_test = x[test_index].reshape(-1,28,28,1)\n",
    "    y_test = y[test_index]\n",
    "    saved_model = cnn()\n",
    "    saved_model.load_weights(\"./best_model.h5\")\n",
    "    saved_model.compile(loss='categorical_crossentropy', optimizer=Adam(), metrics=['acc'])\n",
    "    saved_model.fit(x_train,to_categorical(y_train), validation_data=(x_test,to_categorical(y_test))\n",
    "                , epochs=20,batch_size=1024, callbacks=[model_check_pt,reduce_lr])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "saved_model = cnn()\n",
    "saved_model.load_weights(\"./best_model.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = saved_model.predict(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ImageId</th>\n",
       "      <th>Label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>11</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>12</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>13</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>14</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>15</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>16</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>17</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>18</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>19</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>20</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>21</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>22</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>23</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>24</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>25</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>26</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>27</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>28</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>29</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>30</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70</th>\n",
       "      <td>71</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71</th>\n",
       "      <td>72</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72</th>\n",
       "      <td>73</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73</th>\n",
       "      <td>74</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74</th>\n",
       "      <td>75</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75</th>\n",
       "      <td>76</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76</th>\n",
       "      <td>77</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77</th>\n",
       "      <td>78</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>78</th>\n",
       "      <td>79</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79</th>\n",
       "      <td>80</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80</th>\n",
       "      <td>81</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>81</th>\n",
       "      <td>82</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>82</th>\n",
       "      <td>83</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>83</th>\n",
       "      <td>84</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>84</th>\n",
       "      <td>85</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>85</th>\n",
       "      <td>86</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>86</th>\n",
       "      <td>87</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>87</th>\n",
       "      <td>88</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>88</th>\n",
       "      <td>89</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>89</th>\n",
       "      <td>90</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90</th>\n",
       "      <td>91</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>91</th>\n",
       "      <td>92</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>92</th>\n",
       "      <td>93</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>93</th>\n",
       "      <td>94</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>94</th>\n",
       "      <td>95</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>96</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>97</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>98</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>99</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>100</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    ImageId  Label\n",
       "0         1      2\n",
       "1         2      0\n",
       "2         3      9\n",
       "3         4      0\n",
       "4         5      3\n",
       "5         6      7\n",
       "6         7      0\n",
       "7         8      3\n",
       "8         9      0\n",
       "9        10      3\n",
       "10       11      5\n",
       "11       12      7\n",
       "12       13      4\n",
       "13       14      0\n",
       "14       15      4\n",
       "15       16      3\n",
       "16       17      3\n",
       "17       18      1\n",
       "18       19      9\n",
       "19       20      0\n",
       "20       21      9\n",
       "21       22      1\n",
       "22       23      1\n",
       "23       24      5\n",
       "24       25      7\n",
       "25       26      4\n",
       "26       27      2\n",
       "27       28      7\n",
       "28       29      4\n",
       "29       30      7\n",
       "..      ...    ...\n",
       "70       71      6\n",
       "71       72      5\n",
       "72       73      8\n",
       "73       74      8\n",
       "74       75      2\n",
       "75       76      8\n",
       "76       77      9\n",
       "77       78      9\n",
       "78       79      2\n",
       "79       80      3\n",
       "80       81      5\n",
       "81       82      4\n",
       "82       83      1\n",
       "83       84      0\n",
       "84       85      9\n",
       "85       86      2\n",
       "86       87      4\n",
       "87       88      3\n",
       "88       89      6\n",
       "89       90      7\n",
       "90       91      2\n",
       "91       92      0\n",
       "92       93      6\n",
       "93       94      6\n",
       "94       95      1\n",
       "95       96      4\n",
       "96       97      3\n",
       "97       98      9\n",
       "98       99      7\n",
       "99      100      4\n",
       "\n",
       "[100 rows x 2 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "submission = pd.DataFrame({\"ImageId\":range(1,28001),\n",
    "                          \"Label\":np.argmax(predictions,axis=1)})\n",
    "submission.head(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission.to_csv(\"cnn_digit.csv\",index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
